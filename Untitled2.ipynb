{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dset\n",
    "from IPython.display import display, clear_output\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def status(batch_size, ep, epoch, i, loss, data_loader):\n",
    "    # status\n",
    "    clear_output(wait=True)\n",
    "    print(str(ep) + '/' + str(epoch))\n",
    "    print('batch: ' + str(i+1) + '/' + str(len(data_loader)) + \n",
    "             ' [' + '='*int((i+1)/(len(data_loader)/20)) +\n",
    "              '>' + ' '*(20 - int((i+1)/(len(data_loader)/20))) +\n",
    "              ']')\n",
    "    print('Loss: %.4g '% (loss))\n",
    "    \n",
    "#-------------------------------------------------------------------\n",
    "# this function has been modified in order to accept only BW images\n",
    "def showAllImages(x,y,z):\n",
    "    x = x[1,:,:,:].detach()\n",
    "    y = y[1,:,:,:].detach()\n",
    "    z = z[1,:,:,:].detach()\n",
    "    \n",
    "    x = x.cpu()\n",
    "    x = x.squeeze()\n",
    "    y = y.cpu()\n",
    "    y = y.squeeze()\n",
    "    z = z.cpu()\n",
    "    z = z.squeeze()\n",
    "    \n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(x,cmap='gray')\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(y)\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(z)\n",
    "    plt.show()\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "def conv(dimIn, dimOut):\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(dimIn, dimOut, kernel_size=3, stride=1,\n",
    "                  padding=1),\n",
    "        nn.BatchNorm2d(dimOut),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        nn.Conv2d(dimOut, dimOut, kernel_size=3, stride=1,\n",
    "                 padding=1),\n",
    "        nn.BatchNorm2d(dimOut)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "def pool():\n",
    "    p = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "    return p\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "def invConv(dimIn, dimOut):\n",
    "    model = nn.Sequential(\n",
    "        nn.ConvTranspose2d(dimIn, dimOut, kernel_size=3, stride=2,\n",
    "                           padding=1,output_padding=1),\n",
    "        nn.BatchNorm2d(dimOut),\n",
    "        nn.LeakyReLU(0.2, inplace=True)\n",
    "    )\n",
    "    return model\n",
    "    \n",
    "#-------------------------------------------------------------------\n",
    "def last(dimIn, dimOut):\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(dimIn, dimOut, kernel_size=3, stride=1,\n",
    "                  padding=1),\n",
    "        nn.Tanh()\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetGen(nn.Module):\n",
    "    def __init__(self, filtersNum):\n",
    "        super().__init__()\n",
    "        #self.dimIn = dimIn\n",
    "        #self.dimOut = dimOut\n",
    "        self.fil = filtersNum\n",
    "        \n",
    "        print(\"\\n------Initializing UNetGen------\\n\")\n",
    "        \n",
    "        self.conv1 = conv(1, self.fil)\n",
    "        self.pool1 = pool()\n",
    "        self.conv2 = conv(self.fil, self.fil*2)\n",
    "        self.pool2 = pool()\n",
    "        self.conv3 = conv(self.fil*2, self.fil*4)\n",
    "        self.pool3 = pool()\n",
    "        self.conv4 = conv(self.fil*4, self.fil*8)\n",
    "        self.pool4 = pool()\n",
    "        \n",
    "        self.bridge = conv(self.fil*8, self.fil*16)\n",
    "        \n",
    "        self.inv1 = invConv(self.fil*16, self.fil*8)\n",
    "        self.up1 = conv(self.fil*16, self.fil*8)\n",
    "        self.inv2 = invConv(self.fil*8, self.fil*4)\n",
    "        self.up2 = conv(self.fil*8, self.fil*4)\n",
    "        self.inv3 = invConv(self.fil*4, self.fil*2)\n",
    "        self.up3 = conv(self.fil*4, self.fil*2)\n",
    "        self.inv4 = invConv(self.fil*2, self.fil)\n",
    "        self.up4 = conv(self.fil*2, self.fil)\n",
    "        \n",
    "        self.last = last(self.fil, 1)\n",
    "        \n",
    "    def forward(self, img):\n",
    "        conv1 = self.conv1(img)\n",
    "        pool1 = self.pool1(conv1)\n",
    "        conv2 = self.conv2(pool1)\n",
    "        pool2 = self.pool2(conv2)\n",
    "        conv3 = self.conv3(pool2)\n",
    "        pool3 = self.pool3(conv3)\n",
    "        conv4 = self.conv4(pool3)\n",
    "        pool4 = self.pool4(conv4)\n",
    "        \n",
    "        bridge = self.bridge(pool4)\n",
    "        \n",
    "        inv1 = self.inv1(bridge)\n",
    "        join1 = torch.cat([inv1, conv4],dim=1)\n",
    "        up1 = self.up1(join1)\n",
    "        inv2 = self.inv2(up1)\n",
    "        join2 = torch.cat([inv2, conv3],dim=1)\n",
    "        up2 = self.up2(join2)\n",
    "        inv3 = self.inv3(up2)\n",
    "        join3 = torch.cat([inv3, conv2],dim=1)\n",
    "        up3 = self.up3(join3)\n",
    "        inv4 = self.inv4(up3)\n",
    "        join4 = torch.cat([inv4, conv1],dim=1)\n",
    "        up4 = self.up4(join4)\n",
    "        \n",
    "        res = self.last(up4)\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'TestGen' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-de879e9adde5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./testCNNtraining.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'learningRate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'TestGen' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('./testCNNtraining.pth')\n",
    "model = checkpoint['model']\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "lr = checkpoint['learningRate']\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([3, 6, 2])\n",
    "b = np.tile(a, (2,2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[3 6 2 3 6 2 3 6 2 3 6 2]\n",
      "   [3 6 2 3 6 2 3 6 2 3 6 2]\n",
      "   [3 6 2 3 6 2 3 6 2 3 6 2]]\n",
      "\n",
      "  [[3 6 2 3 6 2 3 6 2 3 6 2]\n",
      "   [3 6 2 3 6 2 3 6 2 3 6 2]\n",
      "   [3 6 2 3 6 2 3 6 2 3 6 2]]]\n",
      "\n",
      "\n",
      " [[[3 6 2 3 6 2 3 6 2 3 6 2]\n",
      "   [3 6 2 3 6 2 3 6 2 3 6 2]\n",
      "   [3 6 2 3 6 2 3 6 2 3 6 2]]\n",
      "\n",
      "  [[3 6 2 3 6 2 3 6 2 3 6 2]\n",
      "   [3 6 2 3 6 2 3 6 2 3 6 2]\n",
      "   [3 6 2 3 6 2 3 6 2 3 6 2]]]] \n",
      " (2, 2, 3, 12)\n"
     ]
    }
   ],
   "source": [
    "print(b, '\\n', b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 6 2 3 6 2 3 6 2 3 6 2]\n",
      " [3 6 2 3 6 2 3 6 2 3 6 2]\n",
      " [3 6 2 3 6 2 3 6 2 3 6 2]]\n"
     ]
    }
   ],
   "source": [
    "print(b[1,1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ep in range(epoch):\n",
    "    for i, (image, label) in enumerate(trainloader):\n",
    "        \n",
    "        print(image.shape)\n",
    "        # add sequence length\n",
    "        image5 = np.tile(image, (6,1,1,1,1))\n",
    "        \n",
    "        print(image5.shape)\n",
    "        \n",
    "        im = image[1,:,:,:]\n",
    "        plt.imshow(im.squeeze())\n",
    "        plt.show()\n",
    "        \n",
    "        im = image5[1,1,:,:,:]\n",
    "        plt.imshow(im.squeeze())\n",
    "        plt.show()\n",
    "        \n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
