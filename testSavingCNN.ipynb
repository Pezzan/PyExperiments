{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dset\n",
    "from IPython.display import display, clear_output\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def status(batch_size, ep, epoch, i, loss, data_loader):\n",
    "    # status\n",
    "    clear_output(wait=True)\n",
    "    print(str(ep) + '/' + str(epoch))\n",
    "    print('batch: ' + str(i+1) + '/' + str(len(data_loader)) + \n",
    "             ' [' + '='*int((i+1)/(len(data_loader)/20)) +\n",
    "              '>' + ' '*(20 - int((i+1)/(len(data_loader)/20))) +\n",
    "              ']')\n",
    "    \n",
    "    #print('Loss: %.4g '% ((loss / ((i+1)*batch_size))))\n",
    "    print('Loss: %.4g '% (loss))\n",
    "    \n",
    "#-------------------------------------------------------------------\n",
    "def showAllImages(x,y,z):\n",
    "    x = x[1,:,:,:].detach()\n",
    "    y = y[1,:,:,:].detach()\n",
    "    z = z[1,:,:,:].detach()\n",
    "    \n",
    "    x = x.cpu()\n",
    "    y = y.cpu()\n",
    "    z = z.cpu()\n",
    "    \n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(np.transpose(x, (1,2,0)))\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(np.transpose(y, (1,2,0)))\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(np.transpose(z, (1,2,0)))\n",
    "    plt.show()\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "def conv(dimIn, dimOut):\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(dimIn, dimOut, kernel_size=3, stride=1,\n",
    "                  padding=1),\n",
    "        nn.BatchNorm2d(dimOut),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        nn.Conv2d(dimOut, dimOut, kernel_size=3, stride=1,\n",
    "                 padding=1),\n",
    "        nn.BatchNorm2d(dimOut)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "def pool():\n",
    "    p = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "    return p\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "def invConv(dimIn, dimOut):\n",
    "    model = nn.Sequential(\n",
    "        nn.ConvTranspose2d(dimIn, dimOut, kernel_size=3, stride=2,\n",
    "                           padding=1,output_padding=1),\n",
    "        nn.BatchNorm2d(dimOut),\n",
    "        nn.LeakyReLU(0.2, inplace=True)\n",
    "    )\n",
    "    return model\n",
    "    \n",
    "#-------------------------------------------------------------------\n",
    "def last(dimIn, dimOut):\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(dimIn, dimOut, kernel_size=3, stride=1,\n",
    "                  padding=1),\n",
    "        nn.Tanh()\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestGen(nn.Module):\n",
    "    def __init__(self, nFilters):\n",
    "        super().__init__()\n",
    "        self.fil = nFilters\n",
    "    \n",
    "        self.conv1 = conv(3, self.fil)\n",
    "        self.pool1 = pool()\n",
    "        \n",
    "        self.bridge = conv(self.fil, self.fil*2)\n",
    "        \n",
    "        self.inv1 = invConv(self.fil*2, self.fil)\n",
    "        self.up1 = conv(self.fil*2, self.fil)\n",
    "        \n",
    "        self.last = last(self.fil, 3)\n",
    "        \n",
    "    def forward(self, img):\n",
    "        conv1 = self.conv1(img)\n",
    "        pool1 = self.pool1(conv1)\n",
    "        \n",
    "        bridge = self.bridge(pool1)\n",
    "        \n",
    "        inv1 = self.inv1(bridge)\n",
    "        join1 = torch.cat([inv1, conv1],dim=1)\n",
    "        up1 = self.up1(join1)\n",
    "        \n",
    "        res = self.last(up1)\n",
    "        return res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "batch_size = 1\n",
    "img_size = 256\n",
    "lr = 0.0005\n",
    "epoch = 1\n",
    "\n",
    "# Generator\n",
    "net = TestGen(24)\n",
    "generator = nn.DataParallel(net)\n",
    "\n",
    "img_dir = \"./maps/\"\n",
    "trainset = dset.ImageFolder(root=img_dir,\n",
    "                            transform = transforms.Compose([\n",
    "                            transforms.Scale(size=img_size),\n",
    "                            transforms.CenterCrop(size=(img_size,\n",
    "                            img_size*2)),\n",
    "                            transforms.ToTensor(),\n",
    "                            ]))\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, \n",
    "                                          num_workers=2)\n",
    "\n",
    "recon_loss_func = nn.MSELoss()\n",
    "gen_optimizer = torch.optim.Adam(net.parameters(),lr=lr)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1\n",
      "batch: 549/549 [====================>]\n",
      "Loss: 5.599e-06 \n"
     ]
    }
   ],
   "source": [
    "for ep in range(epoch):\n",
    "    for i, (image, label) in enumerate(trainloader):\n",
    "        \n",
    "        satel_image, map_image = torch.chunk(image, chunks=2, dim=3)\n",
    "        \n",
    "        gen_optimizer.zero_grad()\n",
    "        \n",
    "        x = Variable(satel_image)\n",
    "        y_ = Variable(map_image)\n",
    "        y = generator.forward(x)\n",
    "        \n",
    "        current_loss = recon_loss_func(y,y_)\n",
    "        current_loss.backward()\n",
    "        gen_optimizer.step()\n",
    "        \n",
    "        # status\n",
    "        status(batch_size, ep+1 , epoch, i, current_loss,\n",
    "               trainloader)   \n",
    "        \n",
    "        # images display\n",
    "        if i%10 == 0:\n",
    "            showAllImages(x,y,y_)\n",
    "            time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model': net,\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': net.state_dict(),\n",
    "            'optimizer_state_dict': gen_optimizer.state_dict(),\n",
    "            'loss': current_loss,\n",
    "            'learningRate': lr\n",
    "            }, './testCNNtraining.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rember to restart kernel before continuing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestGen(nn.Module):\n",
    "    def __init__(self, nFilters):\n",
    "        super().__init__()\n",
    "        self.fil = nFilters\n",
    "    \n",
    "        self.conv1 = conv(3, self.fil)\n",
    "        self.pool1 = pool()\n",
    "        \n",
    "        self.bridge = conv(self.fil, self.fil*2)\n",
    "        \n",
    "        self.inv1 = invConv(self.fil*2, self.fil)\n",
    "        self.up1 = conv(self.fil*2, self.fil)\n",
    "        \n",
    "        self.last = last(self.fil, 3)\n",
    "        \n",
    "    def forward(self, img):\n",
    "        conv1 = self.conv1(img)\n",
    "        pool1 = self.pool1(conv1)\n",
    "        \n",
    "        bridge = self.bridge(pool1)\n",
    "        \n",
    "        inv1 = self.inv1(bridge)\n",
    "        join1 = torch.cat([inv1, conv1],dim=1)\n",
    "        up1 = self.up1(join1)\n",
    "        \n",
    "        res = self.last(up1)\n",
    "        return res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = torch.load('./testCNNmodel.pth')\n",
    "\n",
    "\n",
    "checkpoint = torch.load('./testCNNtraining.pth')\n",
    "model = checkpoint['model']\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "lr = checkpoint['learningRate']\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
