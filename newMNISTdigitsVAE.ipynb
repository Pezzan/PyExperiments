{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.markers import MarkerStyle\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Lambda, Input, Dense\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "image_size = x_train.shape[1] * x_train.shape[1]\n",
    "x_train = np.reshape(x_train, [-1, image_size])\n",
    "x_test = np.reshape(x_test, [-1, image_size])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vae(intermediate_dim=512, latent_dim=2):\n",
    "    \"\"\"\n",
    "    Build VAE\n",
    "    :param intermediate_dim: size of hidden layers of the encoder/decoder\n",
    "    :param latent_dim: latent space size\n",
    "    :returns tuple: the encoder, the decoder, and the full vae\n",
    "    \"\"\"\n",
    "\n",
    "    # encoder first\n",
    "    inputs = Input(shape=(image_size,), name='encoder_input')\n",
    "    x = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "\n",
    "    # latent mean and variance\n",
    "    z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "    z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "    # reparametrization trick for random sampling\n",
    "    # Note the use of the Lambda layer\n",
    "    # At runtime, it will call the sampling function\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "    # full encoder encoder model\n",
    "    encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "    encoder.summary()\n",
    "\n",
    "    # decoder\n",
    "    latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "    x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "    outputs = Dense(image_size, activation='sigmoid')(x)\n",
    "\n",
    "    # full decoder model\n",
    "    decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "    decoder.summary()\n",
    "\n",
    "    # VAE model\n",
    "    outputs = decoder(encoder(inputs)[2])\n",
    "    vae = Model(inputs, outputs, name='vae')\n",
    "\n",
    "    # Loss function\n",
    "    # we start wit the reconstruction loss\n",
    "    reconstruction_loss = binary_crossentropy(inputs, outputs) * image_size\n",
    "\n",
    "    # next is the KL divergence\n",
    "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "\n",
    "    # we combine them in a total loss\n",
    "    vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "    vae.add_loss(vae_loss)\n",
    "\n",
    "    return encoder, decoder, vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args: tuple):\n",
    "    \"\"\"\n",
    "    Reparameterization trick by sampling z from unit Gaussian\n",
    "    :param args: (tensor, tensor) mean and log of variance of q(z|x)\n",
    "    :returns tensor: sampled latent vector z\n",
    "    \"\"\"\n",
    "\n",
    "    # unpack the input tuple\n",
    "    z_mean, z_log_var = args\n",
    "\n",
    "    # mini-batch size\n",
    "    mb_size = K.shape(z_mean)[0]\n",
    "\n",
    "    # latent space size\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "\n",
    "    # random normal vector with mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(mb_size, dim))\n",
    "\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_distribution(encoder,\n",
    "                             x_test,\n",
    "                             y_test,\n",
    "                             batch_size=128):\n",
    "    \"\"\"\n",
    "    Display a 2D plot of the digit classes in the latent space.\n",
    "    We are interested only in z, so we only need the encoder here.\n",
    "    :param encoder: the encoder network\n",
    "    :param x_test: test images\n",
    "    :param y_test: test labels\n",
    "    :param batch_size: size of the mini-batch\n",
    "    \"\"\"\n",
    "    z_mean, _, _ = encoder.predict(x_test, batch_size=batch_size)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "\n",
    "    markers = ('o', 'x', '^', '<', '>', '*', 'h', 'H', 'D', 'd', 'P', 'X', '8', 's', 'p')\n",
    "\n",
    "    for i in np.unique(y_test):\n",
    "        plt.scatter(z_mean[y_test == i, 0], z_mean[y_test == i, 1],\n",
    "                    marker=MarkerStyle(markers[i], fillstyle='none'),\n",
    "                    edgecolors='black')\n",
    "\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generated_images(decoder):\n",
    "    \"\"\"\n",
    "    Display a 2D plot of the generated images.\n",
    "    We only need the decoder, because we'll manually sample the distribution z\n",
    "    :param decoder: the decoder network\n",
    "    \"\"\"\n",
    "\n",
    "    # display a nxn 2D manifold of digits\n",
    "    n = 15\n",
    "    digit_size = 28\n",
    "\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(-4, 4, n)\n",
    "    grid_y = np.linspace(-4, 4, n)[::-1]\n",
    "\n",
    "    # start sampling z1 and z2 in the ranges grid_x and grid_y\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = decoder.predict(z_sample)\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "            slice_i = slice(i * digit_size, (i + 1) * digit_size)\n",
    "            slice_j = slice(j * digit_size, (j + 1) * digit_size)\n",
    "            figure[slice_i, slice_j] = digit\n",
    "\n",
    "    # plot the results\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    start_range = digit_size // 2\n",
    "    end_range = n * digit_size + start_range + 1\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.imshow(figure, cmap='Greys_r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          401920      encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            1026        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            1026        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (None, 2)            0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 403,972\n",
      "Trainable params: 403,972\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_sampling (InputLayer)      (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               1536      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 784)               402192    \n",
      "=================================================================\n",
      "Total params: 403,728\n",
      "Trainable params: 403,728\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 2), (None, 2), (N 403972    \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 784)               403728    \n",
      "=================================================================\n",
      "Total params: 807,700\n",
      "Trainable params: 807,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 36s 605us/step - loss: 196.7160 - val_loss: 170.9488\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 39s 647us/step - loss: 168.5538 - val_loss: 165.5511\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 42s 700us/step - loss: 164.8804 - val_loss: 163.1588\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 43s 709us/step - loss: 162.7457 - val_loss: 161.5928\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 43s 709us/step - loss: 161.2786 - val_loss: 160.5326\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 43s 713us/step - loss: 160.1179 - val_loss: 159.4792\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 42s 707us/step - loss: 159.1503 - val_loss: 158.9936\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 42s 705us/step - loss: 158.3348 - val_loss: 158.2846\n",
      "Epoch 9/50\n",
      "38912/60000 [==================>...........] - ETA: 14s - loss: 157.6804"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    encoder, decoder, vae = build_vae()\n",
    "\n",
    "    vae.compile(optimizer='adam')\n",
    "    vae.summary()\n",
    "\n",
    "    vae.fit(x_train,\n",
    "            epochs=50,\n",
    "            batch_size=128,\n",
    "            validation_data=(x_test, None))\n",
    "\n",
    "    plot_latent_distribution(encoder,\n",
    "                             x_test,\n",
    "                             y_test,\n",
    "                             batch_size=128)\n",
    "\n",
    "    plot_generated_images(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
