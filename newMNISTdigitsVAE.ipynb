{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.markers import MarkerStyle\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Lambda, Input, Dense\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "image_size = x_train.shape[1] * x_train.shape[1]\n",
    "x_train = np.reshape(x_train, [-1, image_size])\n",
    "x_test = np.reshape(x_test, [-1, image_size])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vae(intermediate_dim=512, latent_dim=2):\n",
    "    \"\"\"\n",
    "    Build VAE\n",
    "    :param intermediate_dim: size of hidden layers of the encoder/decoder\n",
    "    :param latent_dim: latent space size\n",
    "    :returns tuple: the encoder, the decoder, and the full vae\n",
    "    \"\"\"\n",
    "\n",
    "    # encoder first\n",
    "    inputs = Input(shape=(image_size,), name='encoder_input')\n",
    "    x = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "\n",
    "    # latent mean and variance\n",
    "    z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "    z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "    # reparametrization trick for random sampling\n",
    "    # Note the use of the Lambda layer\n",
    "    # At runtime, it will call the sampling function\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "    # full encoder encoder model\n",
    "    encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "    encoder.summary()\n",
    "\n",
    "    # decoder\n",
    "    latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "    x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "    outputs = Dense(image_size, activation='sigmoid')(x)\n",
    "\n",
    "    # full decoder model\n",
    "    decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "    decoder.summary()\n",
    "\n",
    "    # VAE model\n",
    "    outputs = decoder(encoder(inputs)[2])\n",
    "    vae = Model(inputs, outputs, name='vae')\n",
    "\n",
    "    # Loss function\n",
    "    # we start wit the reconstruction loss\n",
    "    reconstruction_loss = binary_crossentropy(inputs, outputs) * image_size\n",
    "\n",
    "    # next is the KL divergence\n",
    "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "\n",
    "    # we combine them in a total loss\n",
    "    vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "    vae.add_loss(vae_loss)\n",
    "\n",
    "    return encoder, decoder, vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args: tuple):\n",
    "    \"\"\"\n",
    "    Reparameterization trick by sampling z from unit Gaussian\n",
    "    :param args: (tensor, tensor) mean and log of variance of q(z|x)\n",
    "    :returns tensor: sampled latent vector z\n",
    "    \"\"\"\n",
    "\n",
    "    # unpack the input tuple\n",
    "    z_mean, z_log_var = args\n",
    "\n",
    "    # mini-batch size\n",
    "    mb_size = K.shape(z_mean)[0]\n",
    "\n",
    "    # latent space size\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "\n",
    "    # random normal vector with mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(mb_size, dim))\n",
    "\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
